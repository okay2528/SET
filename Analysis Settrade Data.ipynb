{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "from plotnine.data import *\n",
    "%matplotlib inline\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Get list of company name\n",
    "# ab_list = list(string.ascii_lowercase)\n",
    "ab_list = list(string.ascii_uppercase)\n",
    "cookies = dict(cookies_are='working')\n",
    "list_name = [] \n",
    "for i in ab_list: \n",
    "    list_url = 'https://www.set.or.th/set/commonslookup.do?language=th&country=TH&prefix='+i\n",
    "    with requests.get(list_url, cookies=cookies) as r:\n",
    "        soup = BeautifulSoup(r.text, features='html.parser')\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            if a['href'][:29]=='/set/companyprofile.do?symbol':\n",
    "                stock_name = a['href'][30:-35]\n",
    "                list_name.append(stock_name)\n",
    "    time.sleep(2)\n",
    "len(list_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get research \n",
    "# testlist_name = ['A','AP','MK','ADVANC']\n",
    "cookies = dict(cookies_are='working')\n",
    "col_name = ['No','Broker_name','EPS_Bath_20','%Change20','EPS_Bath_21','%Change21','PE_20','PBV_20','DIV_20'\n",
    "            ,'Target_Price','REC','Update_Date','Rating']\n",
    "no_research = []\n",
    "df_research = pd.DataFrame()\n",
    "\n",
    "for company in list_name:\n",
    "    list_val = []\n",
    "    list_url = 'https://www.settrade.com/AnalystConsensus/C04_10_stock_saa_p1.jsp?txtSymbol='+company+'&ssoPageId=9&selectPage=10'\n",
    "    with requests.get(list_url, cookies=cookies) as r:\n",
    "            soup = BeautifulSoup(r.text, features='html.parser')\n",
    "            div = soup.find('div', class_='table-responsive')\n",
    "            if div <> None:\n",
    "                for td in div.find_all('td'):\n",
    "                    x = td.text\n",
    "                    list_val.append(x)\n",
    "                lst1 = list_val[0::14]\n",
    "                lst2 = list_val[1::14]\n",
    "                lst3 = list_val[2::14]\n",
    "                lst4 = list_val[3::14]\n",
    "                lst5 = list_val[4::14]\n",
    "                lst6 = list_val[5::14]\n",
    "                lst7 = list_val[6::14] \n",
    "                lst8 = list_val[7::14] \n",
    "                lst9 = list_val[8::14] \n",
    "                lst10 = list_val[9::14] \n",
    "                lst11 = list_val[10::14]\n",
    "                lst12 = list_val[11::14]\n",
    "                lst13 = list_val[12::14]\n",
    "                df_com = pd.DataFrame(list(zip(lst1, lst2, lst3, lst4, lst5, lst6, lst7, lst8, lst9, lst10, lst11, lst12, lst13)), \n",
    "                        columns = col_name)\n",
    "                df_com = df_com.loc[df_com['Broker_name'].str[:1].isin(ab_list)]\n",
    "                df_com['Company_name'] = company\n",
    "            else:\n",
    "                no_research.append(company)\n",
    "                df_com = pd.DataFrame(columns=col_name)\n",
    "            df_research = df_research.append(df_com, sort=False)        \n",
    "    time.sleep(1)\n",
    "\n",
    "filename = '2.Settrade/Research.csv'\n",
    "df_research.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Research.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('2.Settrade/')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Broker_name</th>\n",
       "      <th>EPS_Bath_20</th>\n",
       "      <th>%Change20</th>\n",
       "      <th>EPS_Bath_21</th>\n",
       "      <th>%Change21</th>\n",
       "      <th>PE_20</th>\n",
       "      <th>PBV_20</th>\n",
       "      <th>DIV_20</th>\n",
       "      <th>Target_Price</th>\n",
       "      <th>REC</th>\n",
       "      <th>Update_Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CGS</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>96.2</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.97</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>-</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BLS</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-1,085.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>108.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Trading Buy</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>SCBS</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-766.7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>105.0</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-</td>\n",
       "      <td>1.80</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>-</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No Broker_name EPS_Bath_20  %Change20 EPS_Bath_21 %Change21  PE_20 PBV_20  \\\n",
       "0   1         CGS      -0.53          -       -0.02      96.2   -3.2      -    \n",
       "1   2         BLS      -0.83   -1,085.7        0.07     108.4   -2.0    0.4    \n",
       "2   3        SCBS      -0.20     -766.7        0.01     105.0   -8.4    0.4    \n",
       "\n",
       "  DIV_20 Target_Price          REC Update_Date Rating Company_name  \n",
       "0     -         1.97          Hold  2020-05-15      -          AAV  \n",
       "1     -         3.40   Trading Buy  2020-05-15    NaN          AAV  \n",
       "2     -         1.80       Neutral  2020-05-14      -          AAV  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_col = ['Update_Date']\n",
    "df_research = pd.read_csv('Research.csv', parse_dates = date_col)\n",
    "df_research.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAV',\n",
       " 'ACE',\n",
       " 'ADB',\n",
       " 'ADVANC',\n",
       " 'AEONTS',\n",
       " 'AI',\n",
       " 'AIT',\n",
       " 'ALL',\n",
       " 'AMANAH',\n",
       " 'AMATA',\n",
       " 'AMATAV',\n",
       " 'ANAN',\n",
       " 'AOT',\n",
       " 'AP',\n",
       " 'ARROW',\n",
       " 'ASAP',\n",
       " 'ASEFA',\n",
       " 'ASIAN',\n",
       " 'ASK',\n",
       " 'ASP',\n",
       " 'ATP30',\n",
       " 'AU',\n",
       " 'AUCT',\n",
       " 'AWC',\n",
       " 'B-WORK',\n",
       " 'BA',\n",
       " 'BAFS',\n",
       " 'BAM',\n",
       " 'BANPU',\n",
       " 'BAY',\n",
       " 'BBL',\n",
       " 'BCH',\n",
       " 'BCP',\n",
       " 'BCPG',\n",
       " 'BDMS',\n",
       " 'BEAUTY',\n",
       " 'BEC',\n",
       " 'BEM',\n",
       " 'BGC',\n",
       " 'BGRIM',\n",
       " 'BH',\n",
       " 'BIG',\n",
       " 'BJC',\n",
       " 'BJCHI',\n",
       " 'BKD',\n",
       " 'BLA',\n",
       " 'BOFFICE',\n",
       " 'BPP',\n",
       " 'BTS',\n",
       " 'BTSGIF',\n",
       " 'BWG',\n",
       " 'CBG',\n",
       " 'CENTEL',\n",
       " 'CHAYO',\n",
       " 'CHG',\n",
       " 'CK',\n",
       " 'CKP',\n",
       " 'CMAN',\n",
       " 'COL',\n",
       " 'COM7',\n",
       " 'COMAN',\n",
       " 'COTTO',\n",
       " 'CPALL',\n",
       " 'CPF',\n",
       " 'CPN',\n",
       " 'CPNREIT',\n",
       " 'CRC',\n",
       " 'DCC',\n",
       " 'DDD',\n",
       " 'DELTA',\n",
       " 'DIF',\n",
       " 'DOHOME',\n",
       " 'DRT',\n",
       " 'DTAC',\n",
       " 'EA',\n",
       " 'EASTW',\n",
       " 'EGCO',\n",
       " 'EKH',\n",
       " 'EPG',\n",
       " 'ERW',\n",
       " 'ESSO',\n",
       " 'FPT',\n",
       " 'FTE',\n",
       " 'FTREIT',\n",
       " 'GFPT',\n",
       " 'GGC',\n",
       " 'GLOBAL',\n",
       " 'GPSC',\n",
       " 'GULF',\n",
       " 'GUNKUL',\n",
       " 'GVREIT',\n",
       " 'HANA',\n",
       " 'HMPRO',\n",
       " 'HREIT',\n",
       " 'HUMAN',\n",
       " 'ICHI',\n",
       " 'III',\n",
       " 'ILINK',\n",
       " 'ILM',\n",
       " 'INSET',\n",
       " 'INTUCH',\n",
       " 'IRPC',\n",
       " 'IT',\n",
       " 'ITEL',\n",
       " 'IVL',\n",
       " 'JAS',\n",
       " 'JASIF',\n",
       " 'JKN',\n",
       " 'JMART',\n",
       " 'JMT',\n",
       " 'JUBILE',\n",
       " 'JWD',\n",
       " 'KAMART',\n",
       " 'KBANK',\n",
       " 'KCE',\n",
       " 'KKP',\n",
       " 'KSL',\n",
       " 'KTB',\n",
       " 'KTC',\n",
       " 'LH',\n",
       " 'LHFG',\n",
       " 'LPH',\n",
       " 'LPN',\n",
       " 'M',\n",
       " 'MAJOR',\n",
       " 'MAKRO',\n",
       " 'MBAX',\n",
       " 'MBKET',\n",
       " 'MC',\n",
       " 'MCS',\n",
       " 'MEGA',\n",
       " 'MGT',\n",
       " 'MINT',\n",
       " 'MK',\n",
       " 'MODERN',\n",
       " 'MONO',\n",
       " 'MTC',\n",
       " 'NER',\n",
       " 'NETBAY',\n",
       " 'NOBLE',\n",
       " 'NYT',\n",
       " 'ORI',\n",
       " 'OSP',\n",
       " 'PCSGH',\n",
       " 'PDG',\n",
       " 'PLANB',\n",
       " 'PM',\n",
       " 'PR9',\n",
       " 'PRIN',\n",
       " 'PRM',\n",
       " 'PSH',\n",
       " 'PSL',\n",
       " 'PSTC',\n",
       " 'PT',\n",
       " 'PTG',\n",
       " 'PTT',\n",
       " 'PTTEP',\n",
       " 'PTTGC',\n",
       " 'PYLON',\n",
       " 'QH',\n",
       " 'RATCH',\n",
       " 'RBF',\n",
       " 'RJH',\n",
       " 'ROJNA',\n",
       " 'RPH',\n",
       " 'RS',\n",
       " 'SABINA',\n",
       " 'SAMART',\n",
       " 'SAMTEL',\n",
       " 'SAPPE',\n",
       " 'SAT',\n",
       " 'SAWAD',\n",
       " 'SC',\n",
       " 'SCB',\n",
       " 'SCC',\n",
       " 'SCCC',\n",
       " 'SDC',\n",
       " 'SEAFCO',\n",
       " 'SELIC',\n",
       " 'SENA',\n",
       " 'SF',\n",
       " 'SFLEX',\n",
       " 'SHR',\n",
       " 'SINGER',\n",
       " 'SIRI',\n",
       " 'SIS',\n",
       " 'SISB',\n",
       " 'SMPC',\n",
       " 'SPA',\n",
       " 'SPALI',\n",
       " 'SPCG',\n",
       " 'SPF',\n",
       " 'SPRC',\n",
       " 'SPRIME',\n",
       " 'SQ',\n",
       " 'SSP',\n",
       " 'STA',\n",
       " 'STANLY',\n",
       " 'STEC',\n",
       " 'STPI',\n",
       " 'SUPER',\n",
       " 'SUSCO',\n",
       " 'SVI',\n",
       " 'SYNEX',\n",
       " 'SYNTEC',\n",
       " 'TACC',\n",
       " 'TASCO',\n",
       " 'TCAP',\n",
       " 'TEAMG',\n",
       " 'TFFIF',\n",
       " 'TFG',\n",
       " 'THAI',\n",
       " 'THANI',\n",
       " 'THCOM',\n",
       " 'THG',\n",
       " 'THRE',\n",
       " 'THREL',\n",
       " 'TISCO',\n",
       " 'TK',\n",
       " 'TKN',\n",
       " 'TKS',\n",
       " 'TLGF',\n",
       " 'TMB',\n",
       " 'TMT',\n",
       " 'TNH',\n",
       " 'TNP',\n",
       " 'TOA',\n",
       " 'TOP',\n",
       " 'TPCH',\n",
       " 'TPIPL',\n",
       " 'TPIPP',\n",
       " 'TPRIME',\n",
       " 'TQM',\n",
       " 'TRUE',\n",
       " 'TSTH',\n",
       " 'TTW',\n",
       " 'TU',\n",
       " 'TVO',\n",
       " 'TWPC',\n",
       " 'UNIQ',\n",
       " 'UTP',\n",
       " 'VGI',\n",
       " 'VIBHA',\n",
       " 'VNT',\n",
       " 'VRANDA',\n",
       " 'WHA',\n",
       " 'WHART',\n",
       " 'WHAUP',\n",
       " 'WICE',\n",
       " 'WORK',\n",
       " 'YGG',\n",
       " 'ZEN']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_com = df_research.Company_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing All even numbers between 2 and 10 using range()\n",
      "0, 15, 30, 45, "
     ]
    }
   ],
   "source": [
    "print(\"Printing All even numbers between 2 and 10 using range()\")\n",
    "for i in range(0, 46, 15):\n",
    "    print(i, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2.Settrade/Price.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-4e4e0ab89671>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# df_price_all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2.Settrade/Price.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mdf_price_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\Python35\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3227\u001b[0m         )\n\u001b[1;32m-> 3228\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\Python35\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             )\n\u001b[0;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\Python35\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2.Settrade/Price.csv'"
     ]
    }
   ],
   "source": [
    "## get price \n",
    "col_name = ['Date','Open_p','Max_p','Min_p','Avg_p','Close_p','Change_p','%Changep','Volume(k)','Value(m)'\n",
    "            ,'SetIndex','%IndexChange']\n",
    "df_price_all = pd.DataFrame()\n",
    "cookies = dict(cookies_are='working')\n",
    "testlist_name = ['AP','MK']\n",
    "for company in target_com:\n",
    "    for i in range(0, 121, 15):\n",
    "        list_val = []\n",
    "        list_url = 'https://portal.settrade.com/C04_02_stock_historical_p1.jsp?txtSymbol='+company+'&selectPage=2&max=15&offset='+str(i)\n",
    "        with requests.get(list_url, cookies=cookies) as r:\n",
    "                soup = BeautifulSoup(r.text, features='html.parser')\n",
    "                div = soup.find('div', class_='table-responsive')\n",
    "                for td in div.find_all('td'):\n",
    "                    x = td.text\n",
    "                    list_val.append(x)\n",
    "                lst1 = list_val[0::12]\n",
    "                lst2 = list_val[1::12]\n",
    "                lst3 = list_val[2::12]\n",
    "                lst4 = list_val[3::12]\n",
    "                lst5 = list_val[4::12]\n",
    "                lst6 = list_val[5::12]\n",
    "                lst7 = list_val[6::12] \n",
    "                lst8 = list_val[7::12] \n",
    "                lst9 = list_val[8::12] \n",
    "                lst10 = list_val[9::12] \n",
    "                lst11 = list_val[10::12]\n",
    "                lst12 = list_val[11::12]\n",
    "                df_price = pd.DataFrame(list(zip(lst1, lst2, lst3, lst4, lst5, lst6, lst7, lst8, lst9, lst10, lst11, lst12)), \n",
    "                                columns = col_name)\n",
    "                df_price['Company_name'] = company\n",
    "                df_price['Date'] = pd.to_datetime(df_price['Date'])\n",
    "                df_price['page_no'] = int(i/15)\n",
    "        df_price_all = df_price_all.append(df_price)\n",
    "\n",
    "# df_price_all\n",
    "filename = 'Price.csv'\n",
    "df_price_all.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Price.csv'\n",
    "df_price_all.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price_all.Company_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date = df_research.Update_Date.max()\n",
    "earliest_date = df_research.Update_Date.min()\n",
    "print(\"latest_update \" + str(latest_date))\n",
    "print(\"earliest_update \" + str(earliest_date))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_research[df_research['Broker_name']=='YUANTA'].groupby(['REC'])['REC'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather[\"Temp\"] = weather.Temp.astype(float)\n",
    "col_name = ['EPS_Bath_20','%Change20','EPS_Bath_21','%Change21','PE_20','PBV_20','DIV_20','Target_Price']\n",
    "df_research = df_research.fillna(0)\n",
    "df_research[col_name] = df_research[col_name].apply(pd.to_numeric, downcast='float', errors='coerce')\n",
    "# weather[\"Temp\"] = pd.to_numeric(weather.Temp, errors='coerce')\n",
    "# for i in col_name:\n",
    "# #     print(col)\n",
    "#     df_research[i] = pd.to_numeric(df_research.i, errors='coerce')\n",
    "    \n",
    "# # cols = df.select_dtypes(exclude=['float']).columns\n",
    "\n",
    "# df[cols] = df[cols].apply(pd.to_numeric, downcast='float', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_research.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_research.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of data\n",
    "(ggplot(df_research)\n",
    " + aes(x='manufacturer')\n",
    " + geom_bar(size=20)\n",
    " + coord_flip()\n",
    " + labs(y='Count', x='Manufacturer', title='Number of Cars by Make')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how broker recommend -- mostly recommend buy \n",
    "# - Yuanta has lot of - on recommend , lot of trading buy\n",
    "# - CNS has lot of recommend neutral and reduce\n",
    "# - KS give many of outperform market\n",
    "\n",
    "df_plot = df_research\n",
    "broker_list = df_plot['Broker_name'].value_counts().index.tolist()[::-1]\n",
    "broker_cat = pd.Categorical(df_plot['Broker_name'], categories=broker_list)\n",
    "df_plot = df_plot.assign(broker_cat = broker_cat)\n",
    "(\n",
    "    ggplot(df_plot)\n",
    "    + aes(x='broker_cat', fill ='REC')\n",
    "    + geom_bar(size=8)\n",
    "    + scale_x_discrete(limits=broker_list)\n",
    "    + coord_flip()\n",
    "    + labs(y='Count', x='Broker_name', title='Number of researches by broker (remove -)')\n",
    "    + theme_classic()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see how broker recommend -- mostly recommend buy \n",
    "# - Yuanta recommend trading buy more than others\n",
    "# - CNS recommend neutral\n",
    "# - KS give many of outperform market\n",
    "\n",
    "df_plot = df_research.loc[df_research['REC']!='-']\n",
    "broker_list = df_plot['Broker_name'].value_counts().index.tolist()[::-1]\n",
    "broker_cat = pd.Categorical(df_plot['Broker_name'], categories=broker_list)\n",
    "df_plot = df_plot.assign(broker_cat = broker_cat)\n",
    "(\n",
    "    ggplot(df_plot)\n",
    "    + aes(x='broker_cat', fill ='REC')\n",
    "    + geom_bar(size=8)\n",
    "    + scale_x_discrete(limits=broker_list)\n",
    "    + coord_flip()\n",
    "    + labs(y='Count', x='Broker_name', title='Number of researches by broker (remove -)')\n",
    "    + theme_classic()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
